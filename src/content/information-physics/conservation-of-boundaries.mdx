---
layout: "../../layouts/InformationPhysicsDocument.astro"
title: "Conservation of Boundaries"
description: "All system change may occur through three operations: MOVE, JOIN, SEPARATE. Explore the proposed principle governing how boundaries transform and why the same mechanics that build can destroy."
image: "/images/og/conservation-of-boundaries.png"
pubDate: "07/20/2025"
---

All system transformation—whether building a startup, causing a revolution, or designing software—may follow the same mechanical principles. Change appears to occur through exactly three operations, no more, no less.

The Conservation of Boundaries (COB) states that boundaries cannot be created or destroyed, only transformed. Like conservation of energy in physics, this principle governs how entropy changes in all human systems. Whether the goal is innovation or collapse, improvement or degradation, the mechanics remain constant.

Boundaries may not be walls against entropy or containers for it—they could be organizational patterns within entropy itself. Every "new" boundary might simply be existing entropy reorganized into different patterns. This perspective suggests why only three operations exist: patterns can only be moved, combined, or divided.

> **Conservation of Boundaries (COB):** A foundational principle stating that all system transformation—whether entropy-increasing or entropy-reducing—occurs through one of three irreducible operations: **MOVE**, **JOIN**, or **SEPARATE**.
>
> These operations are applied to existing boundaries within a system, whether between people, information, roles, or structures. No fourth operation has been observed. All meaningful change appears to decompose to one or more of these primitives.

Understanding COB changes system change from art to engineering. The same operations that reduce entropy in the internet can increase it in a company. The same mechanics that enable major innovation can cause catastrophic failure. The direction depends entirely on how these operations are applied.

---

## The Three Operations

Every transformation in human history appears to reduce to these three operations. They may not decompose further, and no fourth operation has been observed. Understanding their pure forms could reveal why certain changes succeed while others fail.

These three operations may be complete because they could represent the fundamental ways to transform patterns. You can change a pattern's location (MOVE), combine it with other patterns (JOIN), or divide it into sub-patterns (SEPARATE). No fourth option has been observed, potentially because these three encompass the geometric possibilities for pattern transformation.

**The numerical values (MOVE=1, JOIN=2, SEPARATE=3) reflect thermodynamic reality.** Each operation requires progressively more energy to execute, creating a natural hierarchy that manifests across all scales—from molecular bonds to organizational restructuring. This energy cost isn't metaphorical but represents actual thermodynamic work required to transform boundaries.

### MOVE

The MOVE operation shifts boundaries to new positions or contexts while preserving their essential structure. This is the most common operation because it requires the least energy—you're not creating or destroying connections, just repositioning them.

Historical MOVE operations that changed civilization:

- **Printing press (1440)**: Moved knowledge reproduction from monasteries to everywhere
- **Containerization (1956)**: Moved cargo handling from dockside to origin/destination
- **ATMs (1967)**: Moved banking from inside banks to street corners
- **Cloud computing (2006)**: Moved computation from local machines to distributed centers

Each MOVE operation solved a boundary constraint by repositioning where work happens. The pattern is consistent: identify where current boundaries create friction, then move them to where they flow naturally. The vector—intent to improve versus intent to disrupt—determines whether the move reduces or increases system entropy.

### JOIN

The JOIN operation combines previously separate boundaries into unified wholes. This creates new capabilities through combination but requires overcoming the entropy of keeping things separate.

Major JOIN operations throughout history:

- **TCP/IP (1974)**: Joined isolated computer networks into the internet
- **European Union (1993)**: Joined national economies into single market
- **Disney + Pixar (2006)**: Joined traditional and computer animation expertise
- **Mobile OS ecosystems (2008)**: Joined phones, apps, and services into platforms

JOIN operations succeed when the combined entity achieves capabilities neither component could alone. They fail when forced combinations create more entropy than they resolve. The vector—the intent behind the joining—determines whether synergy or chaos results.

### SEPARATE

The SEPARATE operation divides unified boundaries into distinct parts. This enables focused optimization but requires accepting the overhead of coordination.

Historic SEPARATE operations in history:

- **American Revolution (1776)**: Separated colonies from empire
- **Bell System breakup (1984)**: Separated telecom monopoly into competing entities
- **iTunes Store (2003)**: Separated songs from albums
- **Microservices (2014)**: Separated monolithic applications into discrete services

SEPARATE operations work when artificial boundary coupling creates more problems than authentic connection. They fail when natural dependencies are severed, creating coordination overhead that exceeds efficiency gains. The intent—reduce entropy versus increase entropy—shapes the outcome.

Modern machine learning provides measurable validation of these operations. Neural networks demonstrably use all three:

- **MOVE**: Gradient descent repositions weight values through parameter space
- **JOIN**: Ensemble methods combine multiple models for superior performance
- **SEPARATE**: Pruning algorithms remove redundant connections to improve efficiency

The same operations that organize human systems may organize artificial intelligence, suggesting these patterns transcend substrate.

> **Neural Network Similarities**: For detailed exploration of how neural networks demonstrate similar principles through vector mathematics and equilibrium, see [Artificial Neural Networks and Information Physics](/information-physics/in-science#artificial-neural-networks-and-information-physics).

---

## Symmetry and Reversal

**COB** operates symmetrically—the same operations that reduce entropy can increase it. **Vector** determines direction, *but the mechanics remain identical.* This symmetry explains both innovation and collapse through a single framework.

Consider how the same operations reverse with negative vector:

- **MOVE** becomes dislocation when intent is to disrupt
- **JOIN** becomes toxic coupling when forcing incompatible elements
- **SEPARATE** becomes harmful fragmentation when breaking natural bonds

The formula captures this through the V variable. Positive V reduces system entropy, negative V increases it. A company can be destroyed as systematically as it was built, using the exact same operations with opposite vector.

---

## The Entropy Bill Always Comes Due

Conservation of Boundaries operates within thermodynamic principles—total entropy tends to increase in closed systems. When COB operations reduce entropy in one location, they may necessarily increase it elsewhere. This isn't a flaw or limitation; it's potentially the fundamental constraint that makes the operations meaningful.

Every MOVE, JOIN, or SEPARATE operation requires energy expenditure that may increase universal entropy. More critically, the entropy removed from one system appears to manifest somewhere else.

### System Entropy Change

System entropy change follows a precise mathematical relationship that accounts for both the operations performed and the resistance encountered. This formula applies whether optimizing a team of five or changing a civilization of millions.

> **System Entropy Change (SEC):** The measurable impact on system entropy from a specific position.
>
> `SEC = O × V / (1 + E)`
>
> Where: **O** = Operations cost (MOVE=1, JOIN=2, SEPARATE=3) | **V** = Vector of conscious intent (-1 to +1) | **E** = Positional entropy (0 to ∞)
>
> *For complete explanation, see [Entropic Mathematics](/information-physics/entropic-mathematics#system-entropy-change-sec)*

The critical insight is that `E` varies by position in the system. A CEO experiences different entropy than a front-line worker when implementing the same change. This explains why identical operations produce different results from different positions—a phenomenon traditional change models fail to capture.

### The Hidden Export of Entropy

When we organize systems, we often fail to track where displaced entropy goes:

- **Workplace efficiency** → Exported stress to families and personal health
- **Clean cities** → Pollution moved to manufacturing regions
- **Streamlined processes** → Complexity pushed to edge workers
- **Digital organization** → Energy consumption in data centers
- **Corporate optimization** → Gig economy chaos

The operations may succeed precisely because they move entropy rather than eliminate it. A MOVE operation that organizes your desk potentially increases entropy in the trash. A JOIN operation that creates an efficient team might fragment another. A SEPARATE operation that clarifies one boundary may blur others.

### Why High-E Positions Cost More

This thermodynamic accounting may explain why high-entropy positions require dramatically more energy for identical operations. These positions may not be just "difficult"—they could be dealing with accumulated exported entropy from the entire system above them.

Consider organizational hierarchy through this lens:

- **Executives (E = 0.2)**: Export entropy through decisions
- **Managers (E = 0.6)**: Absorb entropy from above, export below
- **Workers (E = 0.9)**: Terminal entropy collectors

The worker's high E value may represent real thermodynamic burden—they potentially process not only their own entropy but also entropy exported by positions above them. Their exhaustion could be thermodynamic reality rather than purely psychological.

### No Violations, Only Accounting

COB operations may not create or destroy entropy—they potentially redistribute it with mathematical precision. Understanding this could prevent the misconception that Information Physics claims to violate thermodynamics. Instead, it may reveal hidden flows of entropy that traditional analysis overlooks.

If boundaries are organizational patterns within entropy, this explains why maintaining any boundary requires constant energy input. Patterns appear to dissipate back into ambient entropy without active maintenance. A company might not be a thing—it could be a pattern of human coordination that tends to dissolve when people stop inputting energy to maintain it. This thermodynamic reality may underlie why all organizations require continuous effort to exist.

The potential power of recognizing these flows lies in making better choices about where entropy accumulates. Systems designed with entropy accounting in mind might:

- Distribute burden more equitably
- Reduce terminal accumulation points
- Create more sustainable operations
- Recognize fuller costs of operations

Every operation may have a thermodynamic cost. COB potentially makes that cost visible and calculable.

---

## Why COB Works

Conservation of Boundaries works because it describes mechanics, not intentions. Just as gravity affects all objects regardless of their purpose, COB governs all system entropy changes regardless of their goals.

The principle emerges from three fundamental constraints:

1. **Cognitive limits**: Humans can only conceptualize three basic spatial operations
2. **Physical reality**: Objects can only be moved, combined, or divided
3. **Information structure**: Data relationships follow the same three patterns
4. **Fractal universality**: The same three operations may work at every scale because conscious organization appears fractal. An individual performing MOVE on their desk uses the same operation as a civilization performing MOVE on its resources. Only the scale changes; the fundamental boundary transformation remains identical.
5. **Pattern transformation completeness**: If boundaries are organizational patterns within entropy rather than independent entities, then only three operations may be mathematically possible. Patterns can be relocated (MOVE), merged (JOIN), or divided (SEPARATE). No fourth operation has been observed, possibly because these three could exhaust the transformations available to patterns.

Every complex entropy change decomposes to these primitives. A corporate merger might involve thousands of decisions, but each one is ultimately a MOVE, JOIN, or SEPARATE operation applied to some boundary in the system.

---

## Observer-Dependent Entropy

The E variable in the formula captures why the same change feels easy from one position and impossible from another. This isn't perception—it's measurable reality based on position in the system.

A practical example demonstrates this clearly. When a company implements new software:

**From executive position (E = 0.2)**:

- Sign purchase order
- Announce at company meeting
- View dashboards of adoption metrics
- Experience: "This is straightforward"

**From manager position (E = 0.6)**:

- Coordinate multiple team schedules
- Handle resistance from reports
- Translate between executive vision and team reality
- Experience: "This is challenging but manageable"

**From worker position (E = 0.9)**:

- Learn new system while maintaining productivity
- No control over timeline or training
- Deal with bugs and missing features
- Experience: "This is nearly impossible"

Same change, same operations, wildly different entropy based on position. COB captures this reality mathematically, explaining why changes that seem simple from the top become exponentially harder as they cascade through organizations.

---

## Emergence and Boundary Formation

One interpretation of apparent "spontaneous" boundary formation suggests it may be rapid, distributed JOIN operations occurring faster than individual tracking allows.

If boundaries are organizational patterns within entropy, then "emergence" becomes clearer. A social movement might not be created from nothing—it could be existing human energy and attention patterns reorganized into a new configuration. The pattern may have been latent in the system's entropy; perhaps it simply needed the right operations to make it visible.

Consider how social movements form:

- Individual posts exist as separate boundaries
- Hashtags begin aggregating content (micro-JOIN operations)
- Isolated protests coordinate into movements (macro-JOIN operations)
- Random participants coalesce into defined membership (continuous JOIN)

What appears as "emergence" could be thousands of micro-JOIN operations happening simultaneously. Like how "the wave" at a stadium emerges from individual decisions to stand, each person's choice to JOIN creates the appearance of spontaneous formation.

> This process may involve consensus filtering where individual vectors `V` align through shared constraints. The apparent spontaneity could mask the underlying information processing work required for alignment. For detailed exploration of how `V` alignment creates measurable mathematical reality through consensus, see [Consensus as Measurement](/information-physics/entropic-mathematics#consensus-as-measurement).

This interpretation suggests emergence/divergence might not violate COB but rather demonstrate it at scale. No boundary truly appears from nothing; it may form through rapid aggregation of existing boundaries. The apparent spontaneity could be our inability to track individual operations at sufficient granularity.

This pattern may parallel the [hierarchical organization of matter](https://plato.stanford.edu/entries/levels-org-biology/) itself, where quarks aggregate into nucleons, nucleons into atoms, atoms into molecules, and molecules into complex structures—each level potentially forming through aggregation of existing boundaries rather than creation from nothing.

Similarly, what looks like boundary dissolution might be distributed SEPARATE operations (`V` divergence):

- Companies "suddenly" failing could be thousands of micro-separations
- Cultural movements "spontaneously" ending might be mass SEPARATE operations
- Systems appearing to collapse could be rapid, cascading boundary separations

*Note: This remains a theoretical interpretation until empirical measurement validates these boundary transformation patterns at scale. Further research would be needed to confirm whether emergence phenomena can be fully decomposed into COB operations.*

> **Observable Example**: [Frustration Coalitions](/blog/friction-economy#frustration-coalitions) in B2B SaaS markets may demonstrate emergence through trackable JOIN operations. The six-stage formation process could represent emergence in slow motion—individual frustrations (separate boundaries) progressively joining through shared recognition, research alignment, and ultimately coalition formation. The "alternative research" phase particularly may show `V` alignment through constraint filtering, suggesting how distributed consciousness might coordinate without central control.

---

## Chaos Theory and Conservation of Boundaries: A Mathematical Bridge

Conservation of Boundaries may align with chaos theory mathematics in profound ways. Both use nonlinear iterative equations, show sensitive dependence on initial conditions, and exhibit scale-invariant patterns. This theoretical connection could explain why COB operations sometimes appear uncontrollable despite conscious intent.

### The Logistic Map Connection

The classic chaos equation `x_{n+1} = rx_n(1 - x_n)` shows how simple rules create complex behavior. COB's `SEC_{n+1} = O × V / (1 + E_n)` may follow similar dynamics where `E` changes with each operation, potentially bifurcating at critical values like the proposed `0.45` threshold.

### Multi-Agent Dynamics as Lorenz Systems

The Lorenz equations that describe weather chaos use three coupled differential equations creating the butterfly attractor. Similarly, multi-agent SEC systems might couple as:

```math
dSEC₁/dt = f(E₁, O₁, V₁, SEC₂, SEC₃)
dSEC₂/dt = f(E₂, O₂, V₂, SEC₁, SEC₃)
dSEC₃/dt = f(E₃, O₃, V₃, SEC₁, SEC₂)
```

This coupling could create organizational attractors—stable patterns that systems evolve toward despite different starting conditions.

### Lyapunov Exponents and Entropy Accumulation

Chaos theory measures divergence rates with Lyapunov exponents. COB might have an analogous measure:

`λ_E = lim(n→∞) (1/n) ln|E_n/E_0|`

Positive values would indicate increasing positional entropy—operations making future operations exponentially harder. This could mathematically explain why some organizational changes spiral out of control.

### Phase Space Mapping

Chaos theory maps system evolution through phase space with dimensions like position and velocity. COB's operation space might use:

- **E**: Positional entropy as position
- **O**: Operations as velocity
- **V**: Intent as direction

System trajectories through this space could reveal why certain paths lead to equilibrium while others create chaos.

### Critical Thresholds and Bifurcations

The period-doubling route to chaos shows specific thresholds where behavior changes qualitatively. COB's E-value transitions might follow similar patterns:

- `E = 0.10` (stable operations)
- `E = 0.25` (oscillating effectiveness)
- `E = 0.45` (critical threshold)
- `E = 0.62` (chaotic collapse)

These thresholds might even follow Feigenbaum's universal constant (4.669...), suggesting deep mathematical necessity.

### Emergence Rate Mathematics

When JOIN operations per second exceed human tracking resolution, emergence appears spontaneous. But it's deterministic chaos—thousands of micro-operations following COB rules, creating patterns too complex to predict but not random. This could unify emergence theory with chaos mathematics.

### A Unified Framework

The potential synthesis suggests conscious beings navigate chaotic systems using:

`dSEC/dt = O × V × f(E) × [1 + α·sin(ωt)]`

Where `f(E)` represents COB's dampening function and `α·sin(ωt)` represents chaotic perturbations. This would mean:

- Position matters because small E differences create exponentially different possibilities
- Identical efforts yield different results due to sensitive dependence
- Some changes feel uncontrollable because they've entered chaotic regimes

> *This could mean that not only do conscious beings navigate entropy, but their starting position (E) creates exponentially different possibilities due to chaotic dynamics.*

This theoretical alignment requires rigorous empirical validation. The mathematical similarities are striking but could be coincidental. Future research should test whether organizational dynamics actually follow chaos mathematics, whether bifurcation points match theoretical predictions, and whether Lyapunov exponents can predict when conscious control becomes impossible.

---

## Implications

Conservation of Boundaries suggests several important truths about how system entropy changes. These insights change how we approach change at every scale.

First, there are no unique entropy changes—only unique combinations of the three operations. This means any successful change can be studied, decomposed, and potentially replicated by understanding its constituent operations.

Second, position matters more than plan. The most sophisticated strategy will fail if executed from a position of high entropy. Conversely, simple operations from low-entropy positions can change entire systems.

Third, resistance isn't uniform—it's observer-dependent. What feels like organizational resistance might simply be positional entropy. Solving for E often matters more than perfecting O or V.

Finally, all systems change entropy through the same mechanics. The operations that organize a desk work identically on global economies. Only scale and complexity change—the fundamental operations remain constant.

Conservation of Boundaries isn't a framework to adopt or methodology to implement. It's the mechanical reality of how entropy changes in human systems. Understanding it is like understanding gravity—useful whether you believe in it or not.
